解决模型泛化能力不足

$FM(x) = Logistic(\sum_{n}^{i=1}\sum_{n}^{j=1}(h_{i}\cdot h_{j}x_{i}x_{j}+w\cdot x+b))$

其中，x是n维输入向量， w是n维权值向量，b是偏置。FM用隐藏向量的内积$h_{i}\cdot h_{j}$ 取代了$w_{i,j}$作为二次项$x_{i}x_{j}$的权值。括号中就是FM的线性部分。最后施加Logistic函数得到正类概率。

如果以$n$个隐藏向量为列构造矩阵：

$H=(h_{1},h_{2},\cdot\cdot\cdot,h_{n})_{k\times n}$

$H^{T}H$是一个$n \times n$矩阵，其中第i行，第j列元素是$w_{i,j}$的替代，所以FM的计算式为：

$FM(x) = Logistic((x^{T}H^{T}Hx+w\cdot x+b))$

将参数换为$H^{T}H$后，二次部分参数大大减少，模型的自由度降低，防止了过拟合

FM利用隐藏向量为各个特征建立起了联系。那些没有在训练集中发生过直接联系的特征会因为它们都与另一个特征出现过联系而在训练集中产生间接联系，这就是FM之所以能够改善泛化能力的原因